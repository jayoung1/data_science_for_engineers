{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(as_frame = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "df = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df\n",
    "y = digits[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(rf.score(x_train_scaled, y_train))\n",
    "\n",
    "y_pred = rf.predict(x_test_scaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  1  0  0  1  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 52  0  0  0  0  0  1]\n",
      " [ 1  0  0  0 60  1  0  0  0  1]\n",
      " [ 0  0  0  0  0 63  1  0  0  1]\n",
      " [ 0  0  0  0  0  1 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  0]\n",
      " [ 0  0  0  2  0  0  0  0 42  0]\n",
      " [ 0  0  0  0  0  0  0  1  0 56]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(mlp.score(x_train_scaled, y_train))\n",
    "\n",
    "y_pred = mlp.predict(x_test_scaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 47  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 51  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 60  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 64  1  0  1  0]\n",
      " [ 0  0  0  0  0  1 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  0]\n",
      " [ 0  0  0  1  0  0  0  0 42  2]\n",
      " [ 0  0  0  0  0  1  0  1  0 57]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.14269144\n",
      "Iteration 2, loss = 1.70878318\n",
      "Iteration 3, loss = 1.36506763\n",
      "Iteration 4, loss = 1.09726422\n",
      "Iteration 5, loss = 0.89032818\n",
      "Iteration 6, loss = 0.73478779\n",
      "Iteration 7, loss = 0.61578677\n",
      "Iteration 8, loss = 0.52581021\n",
      "Iteration 9, loss = 0.45591908\n",
      "Iteration 10, loss = 0.40108109\n",
      "Iteration 11, loss = 0.35791718\n",
      "Iteration 12, loss = 0.32194704\n",
      "Iteration 13, loss = 0.29207663\n",
      "Iteration 14, loss = 0.26695403\n",
      "Iteration 15, loss = 0.24516612\n",
      "Iteration 16, loss = 0.22611235\n",
      "Iteration 17, loss = 0.20964209\n",
      "Iteration 18, loss = 0.19465836\n",
      "Iteration 19, loss = 0.18150256\n",
      "Iteration 20, loss = 0.16989913\n",
      "Iteration 21, loss = 0.15945397\n",
      "Iteration 22, loss = 0.15015797\n",
      "Iteration 23, loss = 0.14132589\n",
      "Iteration 24, loss = 0.13375637\n",
      "Iteration 25, loss = 0.12649369\n",
      "Iteration 26, loss = 0.11976647\n",
      "Iteration 27, loss = 0.11373365\n",
      "Iteration 28, loss = 0.10787740\n",
      "Iteration 29, loss = 0.10270528\n",
      "Iteration 30, loss = 0.09771407\n",
      "Iteration 31, loss = 0.09300239\n",
      "Iteration 32, loss = 0.08888288\n",
      "Iteration 33, loss = 0.08477460\n",
      "Iteration 34, loss = 0.08109339\n",
      "Iteration 35, loss = 0.07747854\n",
      "Iteration 36, loss = 0.07404096\n",
      "Iteration 37, loss = 0.07096769\n",
      "Iteration 38, loss = 0.06794551\n",
      "Iteration 39, loss = 0.06523922\n",
      "Iteration 40, loss = 0.06263655\n",
      "Iteration 41, loss = 0.06005881\n",
      "Iteration 42, loss = 0.05762649\n",
      "Iteration 43, loss = 0.05546197\n",
      "Iteration 44, loss = 0.05324482\n",
      "Iteration 45, loss = 0.05125667\n",
      "Iteration 46, loss = 0.04939623\n",
      "Iteration 47, loss = 0.04752663\n",
      "Iteration 48, loss = 0.04571084\n",
      "Iteration 49, loss = 0.04407465\n",
      "Iteration 50, loss = 0.04248034\n",
      "Iteration 51, loss = 0.04101735\n",
      "Iteration 52, loss = 0.03961931\n",
      "Iteration 53, loss = 0.03822400\n",
      "Iteration 54, loss = 0.03707166\n",
      "Iteration 55, loss = 0.03584165\n",
      "Iteration 56, loss = 0.03464818\n",
      "Iteration 57, loss = 0.03347197\n",
      "Iteration 58, loss = 0.03237939\n",
      "Iteration 59, loss = 0.03132902\n",
      "Iteration 60, loss = 0.03033033\n",
      "Iteration 61, loss = 0.02940957\n",
      "Iteration 62, loss = 0.02859230\n",
      "Iteration 63, loss = 0.02769962\n",
      "Iteration 64, loss = 0.02688912\n",
      "Iteration 65, loss = 0.02606388\n",
      "Iteration 66, loss = 0.02537303\n",
      "Iteration 67, loss = 0.02463030\n",
      "Iteration 68, loss = 0.02393414\n",
      "Iteration 69, loss = 0.02326794\n",
      "Iteration 70, loss = 0.02265344\n",
      "Iteration 71, loss = 0.02203297\n",
      "Iteration 72, loss = 0.02144323\n",
      "Iteration 73, loss = 0.02089050\n",
      "Iteration 74, loss = 0.02033735\n",
      "Iteration 75, loss = 0.01981350\n",
      "Iteration 76, loss = 0.01928194\n",
      "Iteration 77, loss = 0.01878987\n",
      "Iteration 78, loss = 0.01832396\n",
      "Iteration 79, loss = 0.01786666\n",
      "Iteration 80, loss = 0.01740958\n",
      "Iteration 81, loss = 0.01702341\n",
      "Iteration 82, loss = 0.01659221\n",
      "Iteration 83, loss = 0.01620440\n",
      "Iteration 84, loss = 0.01584570\n",
      "Iteration 85, loss = 0.01548275\n",
      "Iteration 86, loss = 0.01512858\n",
      "Iteration 87, loss = 0.01478433\n",
      "Iteration 88, loss = 0.01446464\n",
      "Iteration 89, loss = 0.01415112\n",
      "Iteration 90, loss = 0.01381496\n",
      "Iteration 91, loss = 0.01352251\n",
      "Iteration 92, loss = 0.01324423\n",
      "Iteration 93, loss = 0.01291506\n",
      "Iteration 94, loss = 0.01266250\n",
      "Iteration 95, loss = 0.01239580\n",
      "Iteration 96, loss = 0.01213103\n",
      "Iteration 97, loss = 0.01188620\n",
      "Iteration 98, loss = 0.01164832\n",
      "Iteration 99, loss = 0.01142201\n",
      "Iteration 100, loss = 0.01118643\n",
      "Iteration 101, loss = 0.01096531\n",
      "Iteration 102, loss = 0.01075717\n",
      "Iteration 103, loss = 0.01054797\n",
      "Iteration 104, loss = 0.01033455\n",
      "Iteration 105, loss = 0.01014235\n",
      "Iteration 106, loss = 0.00994651\n",
      "Iteration 107, loss = 0.00975027\n",
      "Iteration 108, loss = 0.00958070\n",
      "Iteration 109, loss = 0.00940732\n",
      "Iteration 110, loss = 0.00923805\n",
      "Iteration 111, loss = 0.00905860\n",
      "Iteration 112, loss = 0.00889904\n",
      "Iteration 113, loss = 0.00875082\n",
      "Iteration 114, loss = 0.00860576\n",
      "Iteration 115, loss = 0.00845140\n",
      "Iteration 116, loss = 0.00829985\n",
      "Iteration 117, loss = 0.00816270\n",
      "Iteration 118, loss = 0.00801702\n",
      "Iteration 119, loss = 0.00788558\n",
      "Iteration 120, loss = 0.00775993\n",
      "Iteration 121, loss = 0.00764601\n",
      "Iteration 122, loss = 0.00751464\n",
      "Iteration 123, loss = 0.00739881\n",
      "Iteration 124, loss = 0.00728507\n",
      "Iteration 125, loss = 0.00715488\n",
      "Iteration 126, loss = 0.00702862\n",
      "Iteration 127, loss = 0.00692371\n",
      "Iteration 128, loss = 0.00682062\n",
      "Iteration 129, loss = 0.00671982\n",
      "Iteration 130, loss = 0.00662254\n",
      "Iteration 131, loss = 0.00651529\n",
      "Iteration 132, loss = 0.00641068\n",
      "Iteration 133, loss = 0.00631123\n",
      "Iteration 134, loss = 0.00621406\n",
      "Iteration 135, loss = 0.00612045\n",
      "Iteration 136, loss = 0.00602841\n",
      "Iteration 137, loss = 0.00593812\n",
      "Iteration 138, loss = 0.00585387\n",
      "Iteration 139, loss = 0.00577107\n",
      "Iteration 140, loss = 0.00568587\n",
      "Iteration 141, loss = 0.00560446\n",
      "Iteration 142, loss = 0.00551770\n",
      "Iteration 143, loss = 0.00545135\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "1.0\n",
      "0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(verbose = True)\n",
    "\n",
    "mlp.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(mlp.score(x_train_scaled, y_train))\n",
    "\n",
    "y_pred = mlp.predict(x_test_scaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.975925925925926\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes = (100,100,))\n",
    "\n",
    "mlp.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(mlp.score(x_train_scaled, y_train))\n",
    "\n",
    "y_pred = mlp.predict(x_test_scaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
